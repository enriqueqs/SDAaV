{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5d29700fafae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "from folium.plugins import HeatMap\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.io import output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, FactorRange,Legend,LinearAxis, DatetimeTickFormatter, Range1d\n",
    "from bokeh.palettes import Category20\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import factor_cmap\n",
    "from bokeh.resources import CDN\n",
    "from bokeh.embed import file_html\n",
    "from bokeh.plotting import figure, output_file, save\n",
    "from geopy.geocoders import Nominatim\n",
    "from tqdm import tqdm \n",
    "import plotly.express as px\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigation Parking Enforcment Behaviour "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Motivation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: <br>\n",
    "The  data-set  consists  of  NYCâ€™s  records  of  parking  violations  for  the  fiscal  year  2019.   Itcontains information about the violations, such as Car type, Address, Issuer, County, FinedAmount etc.\n",
    "\n",
    "Choice of Dataset:<br>\n",
    "The group wishes to investigate the behavior of Parking Enforcement agents, given that thereis  always  suspicions  from  citizens  regarding  officers  trying  to  meet  quotas.   Since  this  iscommon  myth  in  most  large  cities  in  the  world.   This  data-set  lets  the  group  explore  thebehavior of individual officers and districts.  This gives an opportunity to explore how theyoperate, and clarify if any pattern in their behavior is present.\n",
    "\n",
    "Goal: <br>\n",
    "The goal of this research is to shed light upon the ever lasting question upon the (so called:sneaky) work of parking The goal is to inlighten the reader in the parking violations of New York, and to shed lightupon the ever lasting question upon the (so called:sneaky) work of parking officials. The goalis further to explore the distribution of the violations. How are they located in the city of NewYork, is there any pattern, are any places more prone to the certain type of fines then others.Is there certain month, days or hours people could be more prone to acquire a parking ticket. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Basic Stats\n",
    "**Write about your choices in data cleaning and preprocessing**\n",
    "<br>\n",
    "Through the data cleaning we choose to remove many of the columns as we deemed them not relevant for what we wished to explore thoughout the dataset. Some data was hard to use, since it came in different format. Fx. the time came in xxxxP or xxxxA, here we had to write a small script that converted the time to er 24 hour time format. Day and month were retrived in order to use them for visualizations. Further more, a violation has been taken out of the dataset since it is a speed camera, and we wish to keep i to personel only. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the two data sets, which are the NYC parking violations and the Parking violations codes, which also has the fine amounts etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ameenabutt/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (17,18,20,22,23,29,30,31,32,36,38,39) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Importing the data\n",
    "df = pd.read_csv(\"/Users/ameenabutt/Downloads/Parking_Violations_Issued_-_Fiscal_Year_2019.csv\")\n",
    "codes = pd.read_excel(\"/Users/ameenabutt/Downloads/ParkingViolationCodes_Nov_2018.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data sets are merged on the violation code, and unwanted features are removed, to make the size of the dataset smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the two dataset and removing unwanted features that we don't see any use for i our case\n",
    "#Merging the Data Sets\n",
    "#Convertin Violation code to integer\n",
    "codes[\"VIOLATION CODE\"].astype(int)\n",
    "#df = df.rename(columns={\"Violation Code\": \"Code\"})\n",
    "df_new =  df.merge(codes, left_on=\"Violation Code\",right_on=\"VIOLATION CODE\", how='left')\n",
    "#Dropping Columns that will not be used\n",
    "df = df_new.drop(columns=['Plate ID', 'Registration State', 'Plate Type','Street Code1', 'Street Code2', 'Street Code3','Vehicle Expiration Date', 'Time First Observed', 'Intersecting Street', 'Date First Observed', 'Law Section', 'Sub Division', 'Violation Legal Code', 'Days Parking In Effect',\n",
    "'From Hours In Effect', 'To Hours In Effect', 'Vehicle Color','Violation Precinct','Vehicle Body Type','Feet From Curb','Summons Number','Vehicle Make','Issuing Agency','Unregistered Vehicle?', 'Vehicle Year', 'Meter Number','No Standing or Stopping Violation', 'Hydrant Violation', 'Double Parking Violation',\"Violation Description\",'Violation In Front Of Or Opposite','Violation Location',\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A snippet of code, the converts the time of day to 24hour time slots. As seen in the dataset, hours a signed as xxxxP or xxxxA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting the Violation Time to datetime \n",
    "def time(xx):\n",
    "    time = []\n",
    "    for x in xx:\n",
    "        x = str(x)\n",
    "        if x[-1:] == \"P\":\n",
    "            if x[:2] == \"12\":\n",
    "                new_x = \"12\"\n",
    "                second = x[2:4]\n",
    "                new_time = new_x+\":\"+str(second)+\":\"+\"00\"    \n",
    "                time.append(new_time)\n",
    "            else:\n",
    "                first = int(x[:2])+12\n",
    "                second = x[2:4]\n",
    "                new_time = str(first)+\":\"+str(second)+\":\"+\"00\"   \n",
    "                time.append(new_time)\n",
    "        else:\n",
    "            if x[:2] == \"12\":\n",
    "                new_x = \"00\"\n",
    "                second = x[2:4]\n",
    "                new_time = new_x+\":\"+str(second)+\":\"+\"00\"    \n",
    "                time.append(new_time)\n",
    "            else:  \n",
    "                first = x[:2]\n",
    "                second = x[2:4]\n",
    "                new_time = str(first)+\":\"+str(second)+\":\"+\"00\"    \n",
    "                time.append(new_time)\n",
    "    return time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is cleaned and features added such as days, hours and months. Some values are removed from the strings. Such as the @ from the street names, as they were not recongnized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Converting and cleaning date and time\n",
    "df['Issue Date']=pd.to_datetime(df[\"Issue Date\"], format='%m/%d/%Y', errors='coerce')\n",
    "# Taking only the relevant years, some years were very off\n",
    "df = df.loc[df[\"Issue Date\"].dt.year.isin([\"2018\",\"2019\"])]\n",
    "df[\"Day Name\"] = df[\"Issue Date\"].dt.day_name()\n",
    "df[\"Day Number\"] =  df[\"Issue Date\"].dt.dayofweek\n",
    "df[\"month\"] =  df[\"Issue Date\"].dt.month\n",
    "df[\"month name\"] = df[\"Issue Date\"].dt.month_name()\n",
    "df[\"Time\"] = pd.to_datetime(time(df['Violation Time']), format = '%H:%M:%S',  errors='coerce' )\n",
    "df[\"Hour\"] = df[\"Time\"].dt.hour\n",
    "df.dropna(subset= [\"Hour\"], inplace = True)\n",
    "#Done to be used in Bokeh plot\n",
    "df[\"Hour\"] = df[\"Hour\"].astype(int)\n",
    "df[\"Day\"] = df[\"Issue Date\"].dt.day\n",
    "####### Combning adress information in order get geo location \n",
    "df['Street Name'] = df['Street Name'].replace('@', '', regex=True)\n",
    "df[\"Address\"] = df[\"House Number\"].astype(str)+ \" \" + df[\"Street Name\"] +\" \"+ \"NYC\"\n",
    "######## Cleaning County Wise\n",
    "df.dropna(subset=[\"Violation County\"], inplace=True)\n",
    "df['Violation County'] = df['Violation County'].replace('QUEEN', 'Q', regex=True)\n",
    "df[\"County\"] = df['Violation County'].astype(str)\n",
    "# Creating Time Stamps and time features\n",
    "\n",
    "#Dropping Violation code 36 because it is a Speed Camera\n",
    "df = df[df[\"Violation Code\"] != 36 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the geo location calculation the top 10 Violations are only looked upon, to minimize the data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting top violations, and sampling i to 1% when obtaining geo locations. Even this takes 10 hours. \n",
    "topfines = df[\"VIOLATION DESCRIPTION\"].value_counts()[:10]\n",
    "top = topfines.index.to_list()\n",
    "location_df = df[df[\"VIOLATION DESCRIPTION\"].isin(top)]\n",
    "location_df = location_df.sample(frac=0.01).reset_index()\n",
    "print(\"size of location dataset:\",location_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code takes 10 hours to run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding latitude and lontitude\n",
    "#geolocator = Nominatim(user_agent=\"social\")\n",
    "#\n",
    "#place = []\n",
    "#for i in tqdm(location_df[\"Adress\"]):\n",
    "#    try:\n",
    "#        location = geolocator.geocode(i)\n",
    "#        lat = location.latitude\n",
    "#        lon = location.longitude\n",
    "#        place.append({\"Lat\":lat,\"Lon\":lon})\n",
    "#        df_loc = pd.DataFrame(place)\n",
    "#    except:\n",
    "#        lat = np.nan\n",
    "#        lon = np.nan\n",
    "#        place.append({\"Lat\":lat,\"Lon\":lon})\n",
    "#        df_loc = pd.DataFrame(place)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_df = pd.concat([location_df, df_loc], axis=1)\n",
    "#location_df.to_csv(\"location_data.csv\",sep=\",\")\n",
    "#location_df = pd.read_csv(\"location_data.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#location_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Basic Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Write a short section that discusses the dataset stats, containing key points/plots from your exploratory data analysis. <br>\n",
    "From the data we can clonclude the following:\n",
    " - NY is accountable for 40% og the total revenue out of the top 10 fines\n",
    " - In the monthly plot, we can observe that there is no significant seasonality\n",
    " - New York has **30508** employeed parking enforcement officers \n",
    " - There are **98** different types of parking violations \n",
    " - In total **10318890** parking violations has been  given "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Parking Violations Distribution \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of different parking violatons:\",len(df[\"VIOLATION DESCRIPTION\"].unique()))\n",
    "print(\"Number of county's:\",len(df[\"Violation Precinct\"].unique()))\n",
    "print(\"Number of Postal codes:\", len(df['Violation County'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 most revenued violations\n",
    "top_rev = df.groupby(\"VIOLATION DESCRIPTION\")['Manhattan  96th St. & below\\n(Fine Amount $)'].sum().sort_values(ascending=False)[:10]\n",
    "top_rev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = df.groupby(\"Violation County\")['Manhattan  96th St. & below\\n(Fine Amount $)'].aggregate(['count', 'sum', 'mean']).sort_values(by='sum', ascending=False)\n",
    "analysis               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top 10 most issued fines\n",
    "topfines = df[\"VIOLATION DESCRIPTION\"].value_counts()[:10]\n",
    "topfines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Revenue = df.groupby(['Violation County']).aggregate({'Manhattan  96th St. & below\\n(Fine Amount $)': np.sum}).sort_values(by='Manhattan  96th St. & below\\n(Fine Amount $)', ascending=False)\n",
    "Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct = Revenue['Manhattan  96th St. & below\\n(Fine Amount $)']/sum(Revenue['Manhattan  96th St. & below\\n(Fine Amount $)'])*100\n",
    "pct.sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Revenue on fines\n",
    "sum(Revenue['Manhattan  96th St. & below\\n(Fine Amount $)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Def of bokeh plot\n",
    "def bokeh(df,y):\n",
    "    topfines = df[\"VIOLATION DESCRIPTION\"].value_counts()[:10]\n",
    "    top = topfines.index.to_list()\n",
    "    bokeh = df[df[\"VIOLATION DESCRIPTION\"].isin(top)] #Reducing the dataframe only to obtain the forcuscrimes\n",
    "    station = bokeh.groupby(y)[\"VIOLATION DESCRIPTION\"].value_counts().unstack()\n",
    "    station.reset_index(level=0, inplace=True) # creating a new index, so hour becomes a column. \n",
    "        \n",
    "    source = ColumnDataSource(station)\n",
    "    \n",
    "    hours = [] # empty list to store the string converted hours\n",
    "    for i in sorted(df[y].unique()):\n",
    "        hours.append(str(i))\n",
    "    \n",
    "    p = figure(x_range = FactorRange(factors=hours),plot_height=500, plot_width= 1200, toolbar_location=None, title=\"Distibution of # of fines for top 10 violations pr. {}\".format(y))\n",
    "    bar ={}\n",
    "    items = [] \n",
    "    for indx,i in enumerate(top):\n",
    "        bar[i] = p.vbar(x=y, width=0.2,  top=i, source = source, muted_alpha =0.05, alpha=0.5, muted_color=Category20[14][indx] ,color=Category20[14][indx]) \n",
    "        items.append((i, [bar[i]])) #the dictionary is appended to the items list, to the respective category.  \n",
    "        \n",
    "    legend = Legend(items=items, location=(0,50)) #Legend and location is configured\n",
    "    p.add_layout(legend, \"left\") #Adding the legend outisde the plot. \n",
    "    p.xaxis.axis_label = y #Setting x-axis title\n",
    "    p.yaxis.axis_label = \"# of fines\" #Setting y-axis title\n",
    "    p.x_range.range_padding = 0.05 # \n",
    "    #p.xaxis.major_label_overrides = labels\n",
    "    p.legend.click_policy=\"mute\" #mute is chossen, becuase this enables one to see all of the different categories partily if not chosen, instead of hiding them. \n",
    "    show(p) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh(df,\"Hour\")\n",
    "#Output to html\n",
    "output_file('hour.html', mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh(df,\"month\")\n",
    "\n",
    "#Output to html\n",
    "output_file('month.html', mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh(df,\"Day\")\n",
    "#Output to html\n",
    "output_file('day.html', mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh(df,'County')\n",
    "#Output to html\n",
    "output_file('county.html', mode='inline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(location_df, lat=\"Lat\", lon=\"Lon\",color=\"VIOLATION DESCRIPTION\", zoom=10,width=1200,height=500)\n",
    "fig.update_layout(mapbox_style=\"light\", mapbox_accesstoken=\"pk.eyJ1IjoicmFzbXVzYmxpcnVwIiwiYSI6ImNrYTRjN2FyODA2OXMzZmxicW9ybW8xN2wifQ.wZrS1cwEn0y0TjH2255L5w\")\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.show()\n",
    "pio.write_html(fig, file='map.html', auto_open=True,config={'displayModeBar': False})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Violations Distribution - Conclusion\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Country plot, it is seen that the NY aquires a lot of fines, which can be because of the dense population, and people trying to park everywhere eventhough not allowed. \n",
    "\n",
    "**Monthly plot:** <br>\n",
    "the monthly plot does not really show any seasonal pattern, and is quite steady trhought the month. This could indicate that they do not differentiate on holdidays and other vacations, and people are allways on work. \n",
    "\n",
    "**Daily plot:** <br>\n",
    "The Daily plot has somewhat the same as the monthly, but there is one interesting pattern. The violation **\"INSP. STICKER-EXPIRED/MISSING\"**, has a high count in the first days of a month, and then falls througout the month. This is due to that inspections sticker are aquirred once a year, and monthly done. So the officers will know that by the start of the month, some people might have an expired inspecitons sticker. \n",
    "\n",
    "**Hourly plot:** <br>\n",
    "The hourly plot is the most interresting. It show how the different fines are distributed throughout the days. It is seen that the cleaning tickers are early in the day, just before rush hour begins. Looking at the expired muni meter, it begins at midday. This is interresting because this is also from this point people begin to either go out of the city or home from job, in the interval 12-17. People might have had small erinds which have taken a little more time before, going home. \n",
    "\n",
    "-----\n",
    "\n",
    "What is also mind boggling is the annual return of parking fees i they are paid. A small sum of 856.360.725$, which is alot. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Top Issuers\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_issuer = [\"346199\",\"347607\",\"357052\",\"354144\",\"355542\",\"361794\",\"358632\",\"362237\",\"345162\",\"357358\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df_1 = location_df[location_df[\"Issuer Code\"].isin(top_issuer)]\n",
    "location_df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"Issuer Code\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"Violation Code\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data analysis <br>\n",
    "* Describe your data analysis and explain what you've learned about the dataset.\n",
    "\n",
    "**Violation Distribution**\n",
    "\n",
    "---\n",
    "\n",
    "For the distribution of the top 10 violations, some things where learned. It could be seen that there was no real seasonality in the monthly distribution \n",
    "\n",
    "For the seasonality of the parking violations we can se that the top violation are distributed a little different througout the day. For example the cleaing happens during the start of the day, which means should think about parking right from the morning, instead of just dumping the car anywhere. Another seasonality is the violation \"Inspections Sticker Missing/Outdated\". It is as sticker all cars in New York must have, and is aquired the first once a year. Here it is seen that alot of people aquire it the last or first day of the month, but alot of people forget to get the new inspections sticker in time, and this i seen as alot of people get af fine at the start of the month. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Genre \n",
    "**Which genre of data story did you use?**<br>\n",
    "The goal of the visualization was to engage readers in finding and telling their own stories in the data (section 3.5, Segal and Heer) by using annotated charts, slide show, and a bit of magazine style to set the scene for the readers.<br>\n",
    "\n",
    "**Which tools did you use from each of the 3 categories of Visual Narrative (Figure 7 inSegal and Heer). Why?**<br>\n",
    "The Visual Narrative tool is used to reach and facilitate our goal of the narrative.<br>\n",
    "\n",
    "**From the Visual Structuring** a **consistent visual platformtool** were used through Bokehplots, assuring only to change the content within each frame without changing the general layout. The Bokeh plots were used to engage the reader as a step-by-step approach exploringthrough the data but driven by their own interest. One may argue that a **check-list structure** is used on the Home-page to establishing overview of the over-all content enabling a navigationto particular segment (Top issuer and Violation Distribution).<br>\n",
    "\n",
    "**From the Visual Highlighting** a path is accomplished throughout each sections graphicallyusing color, size, and text style to connect all elements (matching on content). Furthermore,the reader can discoverdetails-on-demandfor the statistics by mousing-over the chart withthe locations and violation descriptions.<br>\n",
    "\n",
    "**From the Transition Guidance** multiple **interactive slideshow** are used (map over the violations and their respectively distribution) in a **single-frame interactivity** to explore the data relatively and to isolate the seasonality of the violations without disorienting the reader. But with the amount of data it was found necessary to divide the data in county, monthly-, daily- and hourly-basis.\n",
    "\n",
    "\n",
    "**Which tools did you use from each of the 3 categories of Narrative Structure (Figure 7 in Segal and Heer). Why?** <br>\n",
    "\n",
    "The Visual Narrative structure tool is used to assist and facilitate our visualization of the narrative.\n",
    "\n",
    "**From the Ordering** a **linear**  and **random** approach is used by giving the reader the option to explore either the issuer or violation. This is done by giving the reader a quick taste of the data-set stats and the main point from the exploratory analysis on the front page. By then choosing which direction the reader wants to dive into. When divining into each sections, a linear approach is used guide the reader through the data. \n",
    "\n",
    "**From the Interactivity** readers are presented multiple interactive plots where they can manipulate the visualization by filtering, zooming and selecting. The instructions are already clear to the reader before the visuals encourage the reader to investigate the data.  \n",
    "\n",
    "**From the Messaging** most of the tools are used, here as Headlines, Annotations, Accompanying Article, Comment Repetition, and Introductory Text. These elements are used to clearly communicate the purpose of the visualizations, and thereby support with relevant observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualizations\n",
    "\n",
    "**Explain the visualizations you've chosen.\n",
    "Why are they right for the story you want to tell?**\n",
    "\n",
    "As mentioned before the goal of the visualization is to engage readers in finding and telling their own stories in the data (section 3.5, Segal and Heer). To balance between the reader and our narrative the graphical elements are mostly interactive graphics (maps and histograms), but ranged with an option for a specific sequence (going from A-Z) or by jumping through the pages or sections on each page. The interactive exploration opportunities encourage the reader to finding and telling their own stories.\n",
    "\n",
    "By using the Martini Glass visualization structure, we go from an author-driven approach to introduce the visualization using an overview of the basic stats, allowing the reader to dig deeper into the data. The basic stats are presented in a table to make it easier to comprehend and to communicate the key observations. \n",
    "Thereafter, leading the reader to interactive components encouraging the reader to investigate, but always making it graphical intuitive to go back and forth between each visualization.   \n",
    "\n",
    "The visual highlighting chosen is to draw the reader to the relevant key observations and there by pointing out features for interaction. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.Discussion \n",
    "* What went well?,\n",
    "* What is still missing? What could be improved?, Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
